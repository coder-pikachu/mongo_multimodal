# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A Next.js 15 application that enables semantic search across visual and textual data using MongoDB Atlas Vector Search, VoyageAI embeddings, and Anthropic Claude AI. Users can upload images and PDFs, which are analyzed by AI and converted into 1024-dimensional vector embeddings for multimodal search.

## Development Commands

```bash
# Development
npm run dev              # Start Next.js development server with Turbopack
npm run build           # Production build
npm run start           # Start production server
npm run lint            # Run ESLint

# Database Operations
npm run test:db         # Test MongoDB connection (runs app/scripts/test-db.ts)
npm run create:index    # Create vector search indexes in MongoDB Atlas (runs app/scripts/create-vector-index.ts)
```

## Architecture

### Service Layer Pattern

The codebase follows a clean service layer architecture to eliminate code duplication:

**Service Layer** (`app/lib/services/`)
- `projectData.service.ts` - All projectData operations (analyze, process, bulk operations)
- `vectorSearch.service.ts` - Unified vector search with configurable strategies

**Route Handlers** (`app/api/`)
- Thin controllers that delegate to service layer
- Consistent error handling
- No business logic duplication

**Utilities** (`app/lib/`)
- `utils.ts` - Re-exports service functions for backward compatibility
- `claude.ts` - LLM response generation
- `voyageai.ts` - Embedding generation
- `mongodb.ts` - Database connection

### Three Interaction Modes

The application provides three distinct ways to interact with data, each using different AI approaches:

1. **Search Mode** (`/api/projects/[projectId]/search`)
   - Direct vector search with pagination
   - Returns top-k results with similarity scores
   - Uses Claude/OpenAI to synthesize results via `lib/claude.ts::generateLLMResponse()`

2. **Chat Mode** (`/api/chat/route.ts`)
   - Conversational Q&A using Vercel AI SDK
   - RAG-enhanced: Performs vector search, then streams response with context
   - Uses `claude-haiku-4-5-20251001` model via `@ai-sdk/anthropic`

3. **Agent Mode** (`/api/agent/route.ts`)
   - LangGraph-inspired agentic workflow with tools
   - Uses Vercel AI SDK's `streamText` with tools: `searchProjectData`, `analyzeImage`, `projectDataAnalysis`
   - Supports multi-step reasoning with `stopWhen: stepCountIs(depth)` parameter
   - Can analyze up to 5 images per query in deep mode
   - Saves conversation history to MongoDB `conversations` collection

### Data Processing Pipeline

1. **Upload** (`/api/projects/[projectId]/upload/route.ts`)
   - Accepts images (JPEG/PNG) and PDFs (max 20MB)
   - Stores raw base64 in MongoDB `projectData` collection
   - Sets `embedding: null` initially

2. **Analysis** (`/api/projects/data/[id]/analyze/route.ts`)
   - Uses Claude or OpenAI (configurable via `LLM_FOR_ANALYSIS` env var) to analyze visual content
   - Extracts description, tags, insights, and facets
   - Stores in `projectData.analysis` field
   - Does NOT generate embeddings (analysis and embedding are separate steps)

3. **Embedding Generation** (`/api/projects/data/[id]/process/route.ts`)
   - Calls `lib/voyageai.ts::generateMultimodalEmbedding()`
   - Sends text and/or base64 image to VoyageAI `voyage-multimodal-3` model
   - Stores 1024-dimensional vector in `projectData.embedding`
   - Sets `processedAt` timestamp

4. **Vector Search**
   - Uses MongoDB Atlas vector search index named `vector_index` on `multimodal.projectData` collection
   - Index configuration: `{ "embedding": { "type": "knnVector", "dimensions": 1024, "similarity": "cosine" } }`
   - Search implementation in `lib/utils.ts::doPaginatedVectorSearch()`

### Key Libraries and Integrations

- **MongoDB**: Connection managed in `lib/mongodb.ts`, uses HMR-safe global caching in development
- **Database Name**: Hardcoded to `"test"` in `lib/mongodb.ts::getDb()` (line 33)
- **VoyageAI**: Multimodal embeddings via `lib/voyageai.ts`, model: `voyage-multimodal-3`
- **Anthropic**: Image analysis and chat via `@ai-sdk/anthropic` and `@anthropic-ai/sdk`
- **OpenAI**: Optional provider for analysis/chat via `@ai-sdk/openai`
- **PDF Processing**: `pdfjs-dist` converts PDFs to images via `lib/pdf-to-image.ts`
- **Image Compression**: `lib/image-utils.ts::compressImage()` optimizes images before analysis to reduce token usage

### Collections Schema

**projects**
```typescript
{
  _id: ObjectId,
  name: string,
  description: string,
  createdAt: Date,
  updatedAt: Date
}
```

**projectData**
```typescript
{
  _id: ObjectId,
  projectId: ObjectId,
  type: 'image' | 'document',
  content: {
    text?: string,      // For documents
    base64?: string     // For images (stored in full resolution)
  },
  metadata: {
    filename: string,
    mimeType: string,
    size: number
  },
  analysis?: {          // Generated by Claude/OpenAI
    description: string,
    tags: string[],
    insights: string[],
    facets: Record<string, any>
  },
  embedding?: number[], // 1024-dimensional vector from VoyageAI
  processedAt?: Date,   // When embedding was generated
  createdAt: Date,
  updatedAt: Date
}
```

**conversations**
```typescript
{
  _id: ObjectId,
  projectId: string,
  sessionId: string,
  message: {
    role: 'user' | 'assistant',
    content: string    // Base64 image data is stripped before saving
  },
  timestamp: Date,
  contentCleaned?: boolean
}
```

## Environment Configuration

Required environment variables in `.env.local`:

```bash
# MongoDB Atlas (M10+ required for vector search)
MONGODB_URI=mongodb+srv://...

# AI Services
VOYAGE_API_KEY=...              # VoyageAI for embeddings
ANTHROPIC_API_KEY=...           # Claude for analysis and chat
OPENAI_API_KEY=...              # Optional, for OpenAI models

# LLM Selection
LLM_FOR_ANALYSIS=claude         # "claude" or "openai" - controls which provider analyzes images

# Optional: LangSmith tracing for agent mode
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=...
LANGCHAIN_PROJECT=...
```

## Service Layer Details

### ProjectData Service (`lib/services/projectData.service.ts`)

Provides centralized functions for all projectData operations:

**Core Functions:**
- `analyzeImageItem(db, itemId)` - Analyze single image with AI (respects `LLM_FOR_ANALYSIS` env var)
- `processItemEmbedding(db, itemId)` - Generate embedding for single item
- `bulkAnalyzeImages(db, projectId, itemIds)` - Validate and queue multiple items for analysis
- `bulkProcessEmbeddings(db, projectId, itemIds)` - Process multiple items in sequence
- `getItemContent(db, itemId)` - Lazy load item content (base64 or text)

**Benefits:**
- Single source of truth for business logic
- Consistent model selection across all routes
- Easier testing and maintenance
- DRY principle - no duplicate code

**Model Selection:**
All analysis functions automatically use the provider specified in `LLM_FOR_ANALYSIS` environment variable:
- `claude` → `claude-haiku-4-5-20251001`
- `openai` → `gpt-5-nano-2025-08-07`

### Vector Search Service (`lib/services/vectorSearch.service.ts`)

Unified vector search implementation with three configurable strategies:

**Core Functions:**
- `performVectorSearch(db, query, queryType, config, projectId?)` - Base search function
- `paginatedVectorSearch(db, projectId, query, type, page, limit)` - Search mode with pagination
- `vectorSearchWithAnalysis(db, query, queryType, projectId?, provider?)` - Search + LLM synthesis

**Search Strategies:**
```typescript
// Paginated (Search Mode)
{ limit: 200, numCandidates: 800, similarityThreshold: 0.3 }

// Analysis (Chat/Legacy Mode)
// Project-specific: { limit: 2, numCandidates: 150, threshold: 0.2 }
// Global: { limit: 10, numCandidates: 300, threshold: 0.2 }

// Agent Mode
{ limit: 2, numCandidates: 150, similarityThreshold: 0.6 }
```

**Benefits:**
- Single implementation for all vector search needs
- Configurable parameters based on use case
- Consistent text boosting for relevance
- Centralized project context handling

### Route Consolidation

**Before Refactoring:**
- `/api/projects/data/[id]/analyze` - 67 lines, duplicate logic
- `/api/projects/data/[id]/process` - 62 lines, duplicate logic
- `/api/projects/[projectId]/data/analyze` - 32 lines, duplicate logic
- `/api/projects/[projectId]/data/process` - 63 lines, duplicate logic

**After Refactoring:**
- Each route: ~20 lines, thin controller
- All business logic in services
- Consistent error handling
- **~80% code reduction in routes**

## Important Implementation Details

### Vector Search Configuration

- **Index Name**: Must be `vector_index` (referenced in search queries)
- **Database**: Hardcoded to `"test"` in `lib/mongodb.ts`
- **Collection**: `projectData`
- **Similarity Threshold**: 0.5 for search mode, 0.6 for agent mode (in `lib/utils.ts`)
- Vector search returns score from 0-1 where higher = more similar

### Agent Mode Tool Usage

The agent uses three tools defined in `/api/agent/route.ts`:

1. **searchProjectData**: Returns top 2 results per call, includes scores and descriptions
2. **analyzeImage**: Fetches image by dataId, compresses it, sends to Claude/OpenAI for context-aware analysis
3. **projectDataAnalysis**: Fetches stored analysis without base64 (faster, uses cached analysis)

Agent system prompt emphasizes:
- **CRITICAL CONSTRAINT**: Only use information from project data via tools (prevents hallucination)
- Never use external knowledge, assumptions, or training data
- Explicitly state when data is not found in the project
- **Step Budget Management**: Agent knows its step limits and plans accordingly
- **Planning Phase**: Agent must plan tool usage BEFORE execution
- Multiple focused tool calls over broad searches
- Iterative refinement (1-2 single-word probes first)
- Mandatory final synthesis step after tool usage
- Project context awareness

The prompt includes explicit hallucination prevention with ❌/✅ rules to enforce data-grounded responses.

### Step Budget System

**How It Works:**
- Each tool call consumes 1 step
- Final text response also consumes 1 step
- Agent MUST reserve the final step for synthesis

**Step Allocation:**
```
General Mode (analysisDepth: 'general'):
- Total: 5 steps
- Tools: Up to 4 steps
- Synthesis: 1 step (mandatory)
- Strategy: 1-2 searches + 1-2 analyses + synthesis

Deep Mode (analysisDepth: 'deep'):
- Total: 8 steps
- Tools: Up to 7 steps
- Synthesis: 1 step (mandatory)
- Strategy: 2-3 searches + 3-4 analyses + synthesis
```

**Planning Phase:**
The agent is instructed to plan BEFORE making any tool calls:
1. Analyze what information is needed
2. Plan which tools to use and in what order
3. Verify sufficient steps remain
4. Prioritize essential information over exhaustive exploration

**Failure Prevention:**
- System prompt explicitly warns: "If you use all steps on tools, you CANNOT provide an answer"
- Agent monitors step usage after each tool call
- Better to synthesize partial results than run out of steps without answering
- If search returns no results, agent tries 1-2 alternatives then concludes (not exhaustive retries)

### Image Compression Strategy

Before sending images to LLMs for analysis (`lib/image-utils.ts`):
- Target: 768px max dimension
- Quality: 85% (JPEG)
- Estimates token usage: ~765 tokens per 1024px image
- Compression reduces API costs and latency

### PDF Handling

PDFs are converted to images page-by-page:
- Each page becomes a separate `projectData` document with `type: 'image'`
- Uses `pdfjs-dist` with canvas rendering
- Original PDF is not stored; only the page images

### Provider Selection

Both Claude and OpenAI are supported. Selection is controlled by `LLM_FOR_ANALYSIS` environment variable:
- **Chat Mode**: Always uses Claude Haiku 4.5 (`claude-haiku-4-5-20251001`)
- **Agent Mode**: Respects `LLM_FOR_ANALYSIS` for tool execution
- **Analysis**: Respects `LLM_FOR_ANALYSIS` for visual content analysis
- OpenAI uses `gpt-5-nano-2025-08-07` when selected

## Testing and Debugging

### Database Connection Test
```bash
npm run test:db
```
Verifies MongoDB URI and lists collections.

### Vector Index Creation
```bash
npm run create:index
```
Creates the required `vector_index` in MongoDB Atlas. Index must be created manually in Atlas UI if script fails (requires M10+ cluster).

### Common Issues

1. **"Vector index not found"**: Run `npm run create:index` or create manually in Atlas
2. **Database name mismatch**: Ensure MongoDB URI database matches `"test"` or update `lib/mongodb.ts::getDb()`
3. **Embedding fails**: Check VoyageAI API key and quota
4. **Analysis fails**: Check Anthropic/OpenAI API keys based on `LLM_FOR_ANALYSIS` setting

## Frontend Structure

- **Project Pages**: `/app/projects/[projectId]/page.tsx` renders tabbed interface
- **Tab Components**: `SearchView.tsx`, `ChatView.tsx`, `AgentView.tsx`, `DataExplorerView.tsx`
- **Data Explorer**: Shows uploaded files with process/analyze buttons
- **Batch Processing**: `BatchProcessButton.tsx` processes multiple files sequentially
- **React Query**: Used for data fetching and cache management via `@tanstack/react-query`

## Code Quality

- **ESLint**: Next.js recommended config
- **TypeScript**: Strict mode enabled
- **Type Definitions**: `app/types/models.ts` and `app/types/clientTypes.ts`
- **Validation**: Zod schemas in `app/lib/validations.ts`
- **Service Layer**: Clean separation of business logic from route handlers
- **DRY Principle**: No code duplication across routes
- **Backward Compatibility**: `utils.ts` re-exports service functions for legacy code

## Recent Optimizations

### Comprehensive Cleanup (Latest)
**Removed Redundant Files (4 deletions):**
- ✅ Deleted `/api/search/route.ts` - Unused global search route (duplicated by project-scoped search)
- ✅ Deleted `/app/myprojects/[projectId]/loading.tsx` - Orphaned loading component with no page
- ✅ Deleted `/api/ask-question/route.ts` - Legacy demo API (functionality in chat/agent)
- ✅ Deleted `/app/vector-search/page.tsx` - Standalone demo page (not part of main app)

**Code Cleanup:**
- ✅ Removed placeholder function `_searchWebHelper` from agent route
- ✅ Removed commented-out web search tool code
- ✅ Fixed missing `doVectorImageSearch` function in `/api/vector-search/route.ts`
- ✅ Fixed unused `projectId` prop in `BatchProcessButton` component
- ✅ All routes now use centralized vector search service
- ✅ Step budget system added to prevent incomplete agent responses

**Architecture Verified:**
- ✅ Dual route pattern (`/projects/data/[id]/` vs `/projects/[projectId]/data/`) is intentional
  - Single-item routes: Individual operations by global ID
  - Bulk routes: Batch operations with project scoping
- ✅ ProcessButton vs BatchProcessButton serve different use cases
- ✅ All service layer functions are actively used (no dead code)

### Service Layer Refactoring
- ✅ Created `projectData.service.ts` for all data operations
- ✅ Created `vectorSearch.service.ts` for unified search logic
- ✅ Reduced route handler code by ~80%
- ✅ Consistent model selection across all endpoints
- ✅ Single source of truth for business logic

## Performance Considerations

- **Vector Search Pagination**: Implemented in `lib/utils.ts::doPaginatedVectorSearch()` to limit result sets
- **Image Compression**: Reduces token usage by ~60-80% before LLM analysis
- **Conversation Storage**: Base64 data is stripped before saving to `conversations` collection to avoid MongoDB document size limits (16MB)
- **HMR Safety**: MongoDB client uses global caching in development to prevent connection pool exhaustion
